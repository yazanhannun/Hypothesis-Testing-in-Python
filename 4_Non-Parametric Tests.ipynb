{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Parametric Tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Assumptions in hypothesis testing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.1 Common assumptions of hypothesis tests</b>\n",
    "\n",
    "Hypothesis tests make assumptions about the dataset that they are testing, and the conclusions you draw from the test results are only valid if those assumptions hold. While some assumptions differ between types of test, others are common to all hypothesis tests.\n",
    "\n",
    "Which of the following statements is a common assumption of hypothesis tests?\n",
    "\n",
    "Possible Answers\n",
    "\n",
    "- Sample observations are collected deterministically from the population.\n",
    "\n",
    "- Sample observations are correlated with each other.\n",
    "\n",
    "- <b><font color ='green'>Sample observations have no direct relationship with each other.</font></b>\n",
    "\n",
    "- Sample sizes are greater than thirty observations.\n",
    "\n",
    "All hypothesis tests assume that the data are collected at random from the population, that each row is independent of the others, and that the sample size is \"big enough\".."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.2 Testing sample size</b>\n",
    "\n",
    "In order to conduct a hypothesis test and be sure that the result is fair, a sample must meet three requirements: it is a random sample of the population, the observations are independent, and there are enough observations. Of these, only the last condition is easily testable with code.\n",
    "\n",
    "The minimum sample size depends on the type of hypothesis tests you want to perform. You'll now test some scenarios on the late_shipments dataset.\n",
    "\n",
    "Note that the .all() method from pandas can be used to check if all elements are true. For example, given a DataFrame df with numeric entries, you check to see if all its elements are less than 5, using (df < 5).all()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "late_shipments = pd.read_feather(\"C:\\\\Users\\\\yazan\\\\Desktop\\\\Data_Analytics\\\\9-Introduction to Hypothesis Testing\\\\Datasets\\\\late_shipments.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expensive     531\n",
      "reasonable    455\n",
      "Name: freight_cost_groups, dtype: int64\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''Get the count of each value in the freight_cost_group column of late_shipments.\n",
    "Insert a suitable number to inspect whether the counts are \"big enough\" for a two sample t-test.'''\n",
    "\n",
    "# Count the freight_cost_group values\n",
    "counts = late_shipments['freight_cost_groups'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(counts)\n",
    "\n",
    "# Inspect whether the counts are big enough\n",
    "print((counts >= 30).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No     939\n",
      "Yes     61\n",
      "Name: late, dtype: int64\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "'''Get the count of each value in the late column of late_shipments.\n",
    "Insert a suitable number to inspect whether the counts are \"big enough\" for a one sample proportion test.'''\n",
    "\n",
    "# Count the late values\n",
    "counts = late_shipments['late'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(counts)\n",
    "\n",
    "# Inspect whether the counts are big enough\n",
    "print((counts >= 10).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vendor_inco_term  freight_cost_groups\n",
      "CIP               reasonable              34\n",
      "                  expensive               16\n",
      "DDP               expensive               55\n",
      "                  reasonable              45\n",
      "DDU               reasonable               1\n",
      "EXW               expensive              423\n",
      "                  reasonable             302\n",
      "FCA               reasonable              73\n",
      "                  expensive               37\n",
      "Name: freight_cost_groups, dtype: int64\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "'''Get the count of each value in the freight_cost_group column of late_shipments grouped by vendor_inco_term.\n",
    "Insert a suitable number to inspect whether the counts are \"big enough\" for a chi-square independence test.'''\n",
    "# Count the values of freight_cost_group grouped by vendor_inco_term\n",
    "counts = late_shipments.groupby('vendor_inco_term')['freight_cost_groups'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(counts)\n",
    "\n",
    "# Inspect whether the counts are big enough\n",
    "print((counts >= 5).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Air            906\n",
      "Ocean           88\n",
      "Air Charter      6\n",
      "Name: shipment_mode, dtype: int64\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "'''Get the count of each value in the shipment_mode column of late_shipments.\n",
    "Insert a suitable number to inspect whether the counts are \"big enough\" for an ANOVA test.'''\n",
    "\n",
    "# Count the shipment_mode values\n",
    "counts = late_shipments['shipment_mode'].value_counts()\n",
    "\n",
    "# Print the result\n",
    "print(counts)\n",
    "\n",
    "# Inspect whether the counts are big enough\n",
    "print((counts >= 30).all())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While randomness and independence of observations can't easily be tested programmatically, you can test that your sample sizes are big enough to make a hypothesis test appropriate. Based on the last result, we should be a little cautious of the ANOVA test results given the small sample size for Air Charter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Non-parametric tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.1 Which parametric test?</b>\n",
    "\n",
    "Which test is a parametric equivalent to the Wilcoxon signed-rank test?\n",
    "\n",
    "Possible Answers:\n",
    "\n",
    "- z-test for a difference in proportions\n",
    "\n",
    "- Chi-square goodness of fit test\n",
    "\n",
    "- <b><font color = 'green'>Paired t-test</font></b>\n",
    "\n",
    "- ANOVA\n",
    "\n",
    "\n",
    " The Wilcoxon signed-rank test works well when the assumptions of a paired t-test aren't met."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2.2 Wilcoxon signed-rank test</b>\n",
    "\n",
    "You'll explore the difference between the proportion of county-level votes for the Democratic candidate in 2012 and 2016 to identify if the difference is significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                T  dof alternative          p-val           CI95%   cohen-d  \\\n",
      "T-test -30.298384  499   two-sided  3.600634e-115  [-7.27, -6.39]  0.454202   \n",
      "\n",
      "              BF10  power  \n",
      "T-test  2.246e+111    1.0  \n"
     ]
    }
   ],
   "source": [
    "import pingouin\n",
    "sample_dem_data = pd.read_feather(\"C:\\\\Users\\\\yazan\\\\Desktop\\\\Data_Analytics\\\\9-Introduction to Hypothesis Testing\\\\Datasets\\\\dem_votes_potus_12_16.feather\")\n",
    "\n",
    "# Conduct a paired t-test on dem_percent_12 and dem_percent_16\n",
    "paired_test_results = pingouin.ttest(x=sample_dem_data['dem_percent_16'],\n",
    "y=sample_dem_data['dem_percent_12'],\n",
    "paired=True,\n",
    "alternative=\"two-sided\") \n",
    "\n",
    "\n",
    "# Print paired t-test results\n",
    "print(paired_test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           W-val alternative         p-val       RBC      CLES\n",
      "Wilcoxon  2401.0   two-sided  1.780396e-77  0.961661  0.644816\n"
     ]
    }
   ],
   "source": [
    "# Conduct a Wilcoxon test on dem_percent_12 and dem_percent_16\n",
    "wilcoxon_test_results = pingouin.wilcoxon(x=sample_dem_data['dem_percent_12'],\n",
    "y=sample_dem_data['dem_percent_16'],\n",
    "alternative=\"two-sided\")\n",
    "\n",
    "# Print Wilcoxon test results\n",
    "print(wilcoxon_test_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the large sample size (500), you obtained similar results here between the parametric t-test and non-parametric Wilcoxon test with a very small p-value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Non-parametric ANOVA and unpaired t-tests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3.1 Wilcoxon-Mann-Whitney</b>\n",
    "\n",
    "Another class of non-parametric hypothesis tests are called rank sum tests. Ranks are the positions of numeric values from smallest to largest. Think of them as positions in running events: whoever has the fastest (smallest) time is rank 1, second fastest is rank 2, and so on.\n",
    "\n",
    "By calculating on the ranks of data instead of the actual values, you can avoid making assumptions about the distribution of the test statistic. It's more robust in the same way that a median is more robust than a mean.\n",
    "\n",
    "One common rank-based test is the Wilcoxon-Mann-Whitney test, which is like a non-parametric t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       U-val alternative     p-val       RBC      CLES\n",
      "MWU  38145.0   two-sided  0.000014 -0.331902  0.665951\n"
     ]
    }
   ],
   "source": [
    "# Select the weight_kilograms and late columns\n",
    "weight_vs_late = late_shipments[['weight_kilograms', 'late']]\n",
    "\n",
    "# Convert weight_vs_late into wide format\n",
    "weight_vs_late_wide = weight_vs_late.pivot(columns='late', values='weight_kilograms')\n",
    "\n",
    "\n",
    "# Run a two-sided Wilcoxon-Mann-Whitney test on weight_kilograms vs. late\n",
    "wmw_test = pingouin.mwu(x = weight_vs_late_wide['Yes'],\n",
    "y=weight_vs_late_wide['No'],\n",
    "alternative='two-sided')\n",
    "\n",
    "# Print the test results\n",
    "print(wmw_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cd85abab4e42ed52d78993b1b54e037968b74145d44eb01d9e116517c8fc42a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
